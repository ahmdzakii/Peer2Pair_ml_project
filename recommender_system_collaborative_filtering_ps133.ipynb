{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fionatjahjono/ml_project/blob/main/recommender_system_collaborative_filtering_ps133.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j7Xf1maAUzZC"
      },
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "!pip install scikit-surprise\n",
        "from flask import Flask, request, jsonify\n",
        "import pandas as pd\n",
        "from surprise import Reader, Dataset\n",
        "from surprise.model_selection import train_test_split, KFold, GridSearchCV\n",
        "from surprise import KNNBasic, KNNWithMeans, KNNWithZScore, KNNBaseline, SVD\n",
        "from surprise import accuracy\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load datasets\n",
        "event_table = pd.read_csv('/content/event_table.csv')\n",
        "sentiment_analysis = pd.read_csv('/content/sentiment_analysis.csv')\n",
        "category_table = pd.read_csv('/content/category_table.csv')"
      ],
      "metadata": {
        "id": "vMdQ7t3nAbuL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Merge data for collaborative filtering\n",
        "merged_data = pd.merge(sentiment_analysis[['event_id', 'user_id', 'rating']], event_table[['event_id', 'event_name', 'category_id']],\n",
        "                       on='event_id')\n",
        "merged_data = pd.merge(merged_data, category_table, on='category_id')"
      ],
      "metadata": {
        "id": "Khbi_T4qAbuL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create Surprise dataset\n",
        "reader = Reader(rating_scale=(1, 5))\n",
        "data = Dataset.load_from_df(merged_data[['user_id', 'event_name', 'rating']], reader)"
      ],
      "metadata": {
        "id": "4mU0MO_UAbuM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split data into training and testing sets\n",
        "trainset, testset = train_test_split(data, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "OmdKpf_cAbuM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a cross-validation iterator\n",
        "kf = KFold(n_splits=5)"
      ],
      "metadata": {
        "id": "Bcwe0XknAbuM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train models with GridSearchCV to find the best parameters\n",
        "param_grid = {'n_epochs': [5, 10], 'lr_all': [0.002, 0.005], 'reg_all': [0.4, 0.6]}\n",
        "gs = GridSearchCV(SVD, param_grid, measures=['rmse', 'mae'], cv=kf)\n",
        "\n",
        "gs.fit(data)"
      ],
      "metadata": {
        "id": "Jc-gqhiEAbuM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Best RMSE score\n",
        "print(gs.best_score['rmse'])"
      ],
      "metadata": {
        "id": "IERo0OyPAbuM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Combination of parameters that gave the best RMSE score\n",
        "print(gs.best_params['rmse'])"
      ],
      "metadata": {
        "id": "Ns0aid_5AbuM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# We can now use the algorithm that yields the best rmse:\n",
        "algo = gs.best_estimator['rmse']\n",
        "algo.fit(data.build_full_trainset())"
      ],
      "metadata": {
        "id": "-c11LdlsAbuN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to generate event recommendations based on popularity\n",
        "def generate_popularity_recommendations(n=10):\n",
        "    event_popularity = merged_data.groupby(['event_name', 'category_name'])['rating'].agg(['mean', 'count']).sort_values(by='mean', ascending=False)\n",
        "    top_events = event_popularity.head(n)\n",
        "    return top_events"
      ],
      "metadata": {
        "id": "jSJ9SDw3AbuN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Flask app\n",
        "app = Flask(__name__)\n",
        "\n",
        "@app.route('/recommend', methods=['POST'])\n",
        "def recommend():\n",
        "    user_id = request.json['user_id']\n",
        "    n = request.json.get('n', 10)\n",
        "    # Generate and print popularity recommendations\n",
        "    popularity_recommendations = generate_popularity_recommendations(n)\n",
        "    return jsonify(popularity_recommendations.to_dict())\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    app.run(debug=True)"
      ],
      "metadata": {
        "id": "_ZCTYcy6AbuN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test data before Flask\n",
        "event_table = pd.read_csv('/content/event_table.csv')\n",
        "sentiment_analysis = pd.read_csv('/content/sentiment_analysis.csv')\n",
        "category_table = pd.read_csv('/content/category_table.csv')"
      ],
      "metadata": {
        "id": "_ThOtp5ZU6ar"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Merge data for collaborative filtering\n",
        "merged_data = pd.merge(sentiment_analysis[['event_id', 'user_id', 'rating']], event_table[['event_id', 'event_name', 'category_id']],\n",
        "                       on='event_id')\n",
        "merged_data = pd.merge(merged_data, category_table, on='category_id')"
      ],
      "metadata": {
        "id": "gWeJOjvHU8vU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create Surprise dataset\n",
        "reader = Reader(rating_scale=(1, 5))\n",
        "data = Dataset.load_from_df(merged_data[['user_id', 'event_name', 'rating']], reader)"
      ],
      "metadata": {
        "id": "MhYVZO3dU9fj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split data into training and testing sets\n",
        "trainset, testset = train_test_split(data, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "_wIRJ-KIU-7z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a cross-validation iterator\n",
        "kf = KFold(n_splits=5)"
      ],
      "metadata": {
        "id": "fh4aNReAWHrE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train models with GridSearchCV to find the best parameters\n",
        "param_grid = {'n_epochs': [5, 10], 'lr_all': [0.002, 0.005], 'reg_all': [0.4, 0.6]}\n",
        "gs = GridSearchCV(SVD, param_grid, measures=['rmse', 'mae'], cv=kf)\n",
        "\n",
        "gs.fit(data)"
      ],
      "metadata": {
        "id": "ApP5yIZ-WNHC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Best RMSE score\n",
        "print(gs.best_score['rmse'])"
      ],
      "metadata": {
        "id": "WY-r85xEVA0r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Combination of parameters that gave the best RMSE score\n",
        "print(gs.best_params['rmse'])"
      ],
      "metadata": {
        "id": "wUeuxUTRVDOC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# We can now use the algorithm that yields the best rmse:\n",
        "algo = gs.best_estimator['rmse']\n",
        "algo.fit(data.build_full_trainset())"
      ],
      "metadata": {
        "id": "8SY0B4IIVD7i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to generate event recommendations based on popularity\n",
        "def generate_popularity_recommendations(n=10):\n",
        "    event_popularity = merged_data.groupby(['event_name', 'category_name'])['rating'].agg(['mean', 'count']).sort_values(by='mean', ascending=False)\n",
        "    top_events = event_popularity.head(n)\n",
        "    return top_events"
      ],
      "metadata": {
        "id": "EbiUJHlsWqRb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate and print popularity recommendations\n",
        "popularity_recommendations = generate_popularity_recommendations()\n",
        "print('\\nTop Event Popularity Recommendations:')\n",
        "print(popularity_recommendations)"
      ],
      "metadata": {
        "id": "B2CILjkxVGQz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}