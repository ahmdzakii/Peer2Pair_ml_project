{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fionatjahjono/ml_project/blob/main/recommender_system_content_based_filtering_ps133.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WxzwuJZfwQn2"
      },
      "outputs": [],
      "source": [
        "from flask import Flask, request, jsonify\n",
        "import pandas as pd\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import numpy as np\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "import re\n",
        "import gensim.downloader\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "app = Flask(__name__)\n",
        "\n",
        "@app.route('/recommend', methods=['POST'])\n",
        "def recommend():\n",
        "    data = request.get_json(force=True)\n",
        "    user_id_to_check = data['user_id']\n",
        "    threshold = data['threshold']"
      ],
      "metadata": {
        "id": "Mlycfc1LBpuo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "    df_user = pd.read_csv(\"/content/user_table.csv\", index_col=0)\n",
        "    df_user = df_user.drop(\"user_name\", axis=1)\n",
        "\n",
        "\n",
        "    df_user"
      ],
      "metadata": {
        "id": "79OukjH4wc_q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "    df_user[['user_interest', 'user_past_event']] = df_user[['user_interest', 'user_past_event']].apply(lambda x: x.str.split(', '))\n",
        "    df_user_expanded = df_user.explode('user_interest').explode('user_past_event')\n",
        "    df_user_expanded['row_number'] = range(1, len(df_user_expanded) + 1)\n",
        "\n",
        "    df_user_expanded\n"
      ],
      "metadata": {
        "id": "cnHqfiN-7sep"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "    df_event = pd.read_csv(\"/content/event_table.csv\", index_col=0)\n",
        "    df_event = df_event.drop([\"index_to_drop\", \"date\", \"event_price\", \"split\"], axis=1)\n",
        "\n",
        "    df_event"
      ],
      "metadata": {
        "id": "HvbFtlyJ2Z9y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "    train, test = train_test_split(df_user, test_size=0.2, random_state=42)\n",
        "\n",
        "    train['user_id'] = train.index.astype(int)\n",
        "    test['user_id'] = test.index.astype(int)"
      ],
      "metadata": {
        "id": "AQNZS6S-6gHP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "    print(\"Number of user in train:\",train.shape[0])\n",
        "    print(\"Number of user in test:\",test.shape[0])"
      ],
      "metadata": {
        "id": "XPxBVwRN-f_W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "    df_event[\"combined\"] = df_event[\"event_name\"] + \" \" + df_event[\"event_description\"]\n",
        "    df_event.combined"
      ],
      "metadata": {
        "id": "UoptFGAV-yPV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "    nltk.download(\"punkt\")\n",
        "    nltk.download(\"stopwords\")"
      ],
      "metadata": {
        "id": "oiKApsBI_Fwk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "    from nltk.corpus import stopwords\n",
        "    from nltk.tokenize import word_tokenize"
      ],
      "metadata": {
        "id": "JdCgMfwW_HRi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "    df_event[\"combined\"] = df_event[\"combined\"].str.lower()\n",
        "    df_event.combined"
      ],
      "metadata": {
        "id": "7A0i4jhb_Ii1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "    def tokenize_text(x):\n",
        "        if pd.isna(x):\n",
        "            return []\n",
        "        x = re.sub(r'\\d+', '', x)\n",
        "        return word_tokenize(x.lower())\n",
        "\n",
        "    df_event[\"tokenized\"] = df_event[\"combined\"].apply(tokenize_text)"
      ],
      "metadata": {
        "id": "1Y4E7SJoA23Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_event[\"tokenized\"]"
      ],
      "metadata": {
        "id": "cL2YbrWXBOKY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "    df_event[\"tokenized\"] = df_event[\"combined\"].apply(tokenize_text)\n",
        "\n",
        "    df_event[\"clean_tokenized\"] = df_event[\"tokenized\"].apply(lambda tokens: [word for word in tokens if word.isalpha() and word not in stopwords.words(\"english\")])\n",
        "    df_event.drop(columns=[\"combined\", \"tokenized\"], inplace=True)"
      ],
      "metadata": {
        "id": "vEF-SiCQBQfj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "    glove = gensim.downloader.load('glove-wiki-gigaword-100')"
      ],
      "metadata": {
        "id": "hREt8JLRBUFe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "    def get_embedding(list_of_tokens):\n",
        "        embeddings = np.zeros(100)\n",
        "        for token in list_of_tokens:\n",
        "            if token in glove:\n",
        "                embeddings += glove[token]\n",
        "        return embeddings"
      ],
      "metadata": {
        "id": "rpum90CGDYkv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "    df_event[\"embedding\"] = df_event[\"clean_tokenized\"].apply(lambda x: get_embedding(x))"
      ],
      "metadata": {
        "id": "OLLndIc7DZjE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "    df_event[\"embedding\"]"
      ],
      "metadata": {
        "id": "DmxqkMTvDb0J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "    # for user_id = 1\n",
        "    u = 1\n",
        "    user_data = train[train[\"user_id\"] == u]\n",
        "    # Combine user interests and past events\n",
        "    items_of_user_1 = user_data[\"user_interest\"].explode().astype(int).values\n",
        "    past_events_of_user_1 = user_data[\"user_past_event\"].explode().astype(int).values\n",
        "    combined_items_of_user_1 = np.concatenate((items_of_user_1, past_events_of_user_1))\n",
        "\n",
        "    embedding_of_events_of_user = df_event.loc[df_event.category_id.isin(items_of_user_1), \"embedding\"]\n",
        "    profile_user = np.sum(embedding_of_events_of_user.values)\n",
        "\n",
        "    profile_user = np.sum(embedding_of_events_of_user.values)\n",
        "    profile_user\n",
        "\n",
        "    profile_user.shape\n",
        "\n",
        "    df_event[\"cosine\"] = df_event.embedding.apply(lambda x: cosine_similarity(profile_user.reshape(1, 100), x.reshape(1, 100))).apply(lambda x: x[0][0])\n",
        "    df_event_top50 = df_event.sort_values(\"cosine\", ascending=False).head(50)\n",
        "    top50item = df_event_top50.index.values\n",
        "\n",
        "    top50item = df_event.reset_index().sort_values(\"cosine\", ascending=False).head(50).iloc[:, 0].values\n",
        "    top50item\n",
        "\n",
        "    print(test.dtypes)"
      ],
      "metadata": {
        "id": "B9ciB0N8EE-p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "    # Display top 50 recommended items for the user in the test set\n",
        "    df_event_top50.head(10)\n",
        "\n",
        "    if user_id_to_check not in test[\"user_id\"].values:\n",
        "        return jsonify({\"error\": f\"User {user_id_to_check} does not exist in the test data.\"})\n",
        "    else:\n",
        "        relevant_items_above_threshold = df_event_top50[df_event_top50[\"cosine\"] > threshold].index.values\n",
        "        return jsonify({\"Recommend Event\": relevant_items_above_threshold.tolist()})\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    app.run(debug=True)"
      ],
      "metadata": {
        "id": "I0__Wf8RK58Y"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}